sd_mdiff = sd (this_run[,2] - this_run[,1])
dz = mdiff / sd_mdiff
dz_sem = sd_mdiff / sqrt(sample_size - 1)
dz_moe = qt(0.975, sample_size - 1) * dz_sem
dz_low = dz - dz_moe
dz_high = dz + dz_moe
dz_better_object <- escalc(measure="SMCR", m1i=mean(this_run, 1), m2i=mean(this_run[,2]), sd1i=sd_mdiff, ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
dz_better_object <- rma(dz_better_object$yi, dz_better_object$vi)
dz_better_low = dz_better_object$ci.lb
dz_better_high = dz_better_object$ci.ub
View(cohendz_true_better_obtject)
dz
dz_better_object
dz_better_object <- escalc(measure="SMCR", m1i=mean(this_run[,1]), m2i=mean(this_run[,2]), sd1i=sd_mdiff, ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
dz_better_object <- rma(dz_better_object$yi, dz_better_object$vi)
dz_better_low = dz_better_object$ci.lb
dz_better_high = dz_better_object$ci.ub
dz_better_object
library("MASS")
library("metafor")
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 10
posttest_mean = 5
ws_correlation = 0.6
pretest_sd = 1
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 10
posttest_mean = 1
ws_correlation = 0.6
pretest_sd = 1
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 10
posttest_mean = 1
ws_correlation = 0.6
pretest_sd = 6
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
library("MASS")
library("metafor")
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 10
posttest_mean = 1
ws_correlation = 0.6
pretest_sd = 6
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
cohendz_true_better_obtject
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 10
posttest_mean = 1
ws_correlation = 0.6
pretest_sd = 6
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 50
posttest_mean = 1
ws_correlation = 0.6
pretest_sd = 6
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 100
posttest_mean = 1
ws_correlation = 0.6
pretest_sd = 6
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 100
posttest_mean = 6
ws_correlation = 0.6
pretest_sd = 1
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 20
posttest_mean = 6
ws_correlation = 0.6
pretest_sd = 1
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
source('C:/Users/bob/Dropbox/ITNS/APS 2017/cohend_dz.R', echo=TRUE)
dz_capture = 0
dz_better_capture = 0
d_capture = 0
samples_drawn = 0
this_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =FALSE)
mdiff = mean(this_run[,2]) - mean(this_run, 1)
sd_mdiff = sd (this_run[,2] - this_run[,1])
dz = mdiff / sd_mdiff
dz_sem = sd_mdiff / sqrt(sample_size - 1)
dz_moe = qt(0.975, sample_size - 1) * dz_sem
dz_low = dz - dz_moe
dz_high = dz + dz_moe
dz_better_object <- escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sd_mdiff, ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
dz_better_object <- rma(dz_better_object$yi, dz_better_object$vi)
dz_better_low = dz_better_object$ci.lb
dz_better_high = dz_better_object$ci.ub
dz_better_object
library("MASS")
library("metafor")
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 20
posttest_mean = 6
ws_correlation = 0.6
pretest_sd = 1
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
dz_capture = 0
dz_better_capture = 0
d_capture = 0
samples_drawn = 0
this_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =FALSE)
mdiff = mean(this_run[,2]) - mean(this_run[, 1])
sd_mdiff = sd (this_run[,2] - this_run[,1])
dz = mdiff / sd_mdiff
dz_sem = sd_mdiff / sqrt(sample_size - 1)
dz_moe = qt(0.975, sample_size - 1) * dz_sem
dz_low = dz - dz_moe
dz_high = dz + dz_moe
dz_better_object <- escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sd_mdiff, ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
dz_better_object <- rma(dz_better_object$yi, dz_better_object$vi)
dz_better_low = dz_better_object$ci.lb
dz_better_high = dz_better_object$ci.ub
mean(this_run[,2])
dz_better_object
d_object <-escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sqrt( (sd(this_run[,1]^2 + sd(this_run[,2]^2) )/ 2) ), ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
d_object <- rma(d_object$yi, d_object$vi)
d_low = d_object$ci.lb
d_high = d_object$ci.ub
d_object
if ((dz_low < cohendz_true) && (dz_high > cohend_true)) {dz_capture = dz_capture + 1}
if ((dz_better_low < cohendz_true_better) && (dz_better_high > cohendz_true_better)) {dz_better_capture = dz_better_capture + 1}
library("MASS")
library("metafor")
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 20
posttest_mean = 6
ws_correlation = 0.6
pretest_sd = 1
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
dz_capture = 0
dz_better_capture = 0
d_capture = 0
samples_drawn = 0
this_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =FALSE)
mdiff = mean(this_run[,2]) - mean(this_run[, 1])
sd_mdiff = sd (this_run[,2] - this_run[,1])
dz = mdiff / sd_mdiff
dz_sem = sd_mdiff / sqrt(sample_size - 1)
dz_moe = qt(0.975, sample_size - 1) * dz_sem
dz_low = dz - dz_moe
dz_high = dz + dz_moe
dz_better_object <- escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sd_mdiff, ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
dz_better_object <- rma(dz_better_object$yi, dz_better_object$vi)
dz_better_low = dz_better_object$ci.lb
dz_better_high = dz_better_object$ci.ub
d_object <-escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sqrt( (sd(this_run[,1]^2 + sd(this_run[,2]^2) )/ 2) ), ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
d_object <- rma(d_object$yi, d_object$vi)
d_low = d_object$ci.lb
d_high = d_object$ci.ub
if ((dz_low <= cohendz_true) && (dz_high >= cohend_true)) {dz_capture = dz_capture + 1}
if ((dz_better_low <= cohendz_true_better) && (dz_better_high >= cohendz_true_better)) {dz_better_capture = dz_better_capture + 1}
if ((d_low <= cohend_true) && (d_high >= cohend_true)) {d_capture = d_capture + 1}
samples_drawn = samples_drawn + 1
#install.packages("MASS")
#install.packages("metafor")
library("MASS")
library("metafor")
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 20
posttest_mean = 6
ws_correlation = 0.6
pretest_sd = 1
#for (sample_size in c(10, 15, 20, 25, 30, 35, 40, 45, 50)) {
#  for (posttest_mean in c(5, 5.5, 6, 6.5)) {
#    for (ws_correlation in c(0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)) {
#      for (pretest_sd in c(1, 1.5, 2)) {
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
#population values
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
#Now draw samples
dz_capture = 0
dz_better_capture = 0
d_capture = 0
samples_drawn = 0
#      for(samples in 1:samples_per_condition) {
this_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =FALSE)
mdiff = mean(this_run[,2]) - mean(this_run[, 1])
#calculate dz and its CI as Masson emailed
sd_mdiff = sd (this_run[,2] - this_run[,1])
dz = mdiff / sd_mdiff
dz_sem = sd_mdiff / sqrt(sample_size - 1)
dz_moe = qt(0.975, sample_size - 1) * dz_sem
dz_low = dz - dz_moe
dz_high = dz + dz_moe
#calculate dz and its CI as Bob suggests
dz_better_object <- escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sd_mdiff, ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
dz_better_object <- rma(dz_better_object$yi, dz_better_object$vi)
dz_better_low = dz_better_object$ci.lb
dz_better_high = dz_better_object$ci.ub
d_object <-escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sqrt( (sd(this_run[,1]^2 + sd(this_run[,2]^2) )/ 2) ), ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
d_object <- rma(d_object$yi, d_object$vi)
d_low = d_object$ci.lb
d_high = d_object$ci.ub
if ((dz_low <= cohendz_true) && (dz_high >= cohend_true)) {dz_capture = dz_capture + 1}
if ((dz_better_low <= cohendz_true_better) && (dz_better_high >= cohendz_true_better)) {dz_better_capture = dz_better_capture + 1}
if ((d_low <= cohend_true) && (d_high >= cohend_true)) {d_capture = d_capture + 1}
samples_drawn = samples_drawn + 1
#      }
print(paste("N=", sample_size, "TrueMeanDiff=", mdiff_true, "Paired_Correlation=", ws_correlation, "SD=", pretest_sd, "Capture of Cohen dz=", dz_capture/samples_drawn, "Capture Bob's way=", dz_better_capture/samples_drawn, "Capture cohen's d", d_capture/samples_drawn, sep=" "))
#}
#}
#}
#}
#install.packages("MASS")
#install.packages("metafor")
library("MASS")
library("metafor")
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 20
posttest_mean = 6
ws_correlation = 0.6
pretest_sd = 1
#for (sample_size in c(10, 15, 20, 25, 30, 35, 40, 45, 50)) {
#  for (posttest_mean in c(5, 5.5, 6, 6.5)) {
#    for (ws_correlation in c(0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)) {
#      for (pretest_sd in c(1, 1.5, 2)) {
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
#population values
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
#Now draw samples
dz_capture = 0
dz_better_capture = 0
d_capture = 0
samples_drawn = 0
#      for(samples in 1:samples_per_condition) {
this_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =FALSE)
mdiff = mean(this_run[,2]) - mean(this_run[, 1])
#calculate dz and its CI as Masson emailed
sd_mdiff = sd (this_run[,2] - this_run[,1])
dz = mdiff / sd_mdiff
dz_sem = sd_mdiff / sqrt(sample_size - 1)
dz_moe = qt(0.975, sample_size - 1) * dz_sem
dz_low = dz - dz_moe
dz_high = dz + dz_moe
#calculate dz and its CI as Bob suggests
dz_better_object <- escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sd_mdiff, ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
dz_better_object <- rma(dz_better_object$yi, dz_better_object$vi)
dz_better_low = dz_better_object$ci.lb
dz_better_high = dz_better_object$ci.ub
d_object <-escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sqrt( (sd(this_run[,1]^2 + sd(this_run[,2]^2) )/ 2) ), ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
d_object <- rma(d_object$yi, d_object$vi)
d_low = d_object$ci.lb
d_high = d_object$ci.ub
if ((dz_low <= cohendz_true) && (dz_high >= cohend_true)) {dz_capture = dz_capture + 1}
if ((dz_better_low <= cohendz_true_better) && (dz_better_high >= cohendz_true_better)) {dz_better_capture = dz_better_capture + 1}
if ((d_low <= cohend_true) && (d_high >= cohend_true)) {d_capture = d_capture + 1}
samples_drawn = samples_drawn + 1
#      }
print(paste("N=", sample_size, "TrueMeanDiff=", mdiff_true, "Paired_Correlation=", ws_correlation, "SD=", pretest_sd, "Capture of Cohen dz=", dz_capture/samples_drawn, "Capture Bob's way=", dz_better_capture/samples_drawn, "Capture cohen's d", d_capture/samples_drawn, sep=" "))
#}
#}
#}
#}
#install.packages("MASS")
#install.packages("metafor")
library("MASS")
library("metafor")
pretest_mean = 5    #arbitrary value for pre-test mean
samples_per_condition = 1000   # number of samples in sampling distribution
sample_size = 20
posttest_mean = 6
ws_correlation = 0.6
pretest_sd = 1
#for (sample_size in c(10, 15, 20, 25, 30, 35, 40, 45, 50)) {
#  for (posttest_mean in c(5, 5.5, 6, 6.5)) {
#    for (ws_correlation in c(0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)) {
#      for (pretest_sd in c(1, 1.5, 2)) {
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
#population values
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
#Now draw samples
dz_capture = 0
dz_better_capture = 0
d_capture = 0
samples_drawn = 0
for(samples in 1:samples_per_condition) {
this_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =FALSE)
mdiff = mean(this_run[,2]) - mean(this_run[, 1])
#calculate dz and its CI as Masson emailed
sd_mdiff = sd (this_run[,2] - this_run[,1])
dz = mdiff / sd_mdiff
dz_sem = sd_mdiff / sqrt(sample_size - 1)
dz_moe = qt(0.975, sample_size - 1) * dz_sem
dz_low = dz - dz_moe
dz_high = dz + dz_moe
#calculate dz and its CI as Bob suggests
dz_better_object <- escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sd_mdiff, ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
dz_better_object <- rma(dz_better_object$yi, dz_better_object$vi)
dz_better_low = dz_better_object$ci.lb
dz_better_high = dz_better_object$ci.ub
d_object <-escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sqrt( (sd(this_run[,1]^2 + sd(this_run[,2]^2) )/ 2) ), ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
d_object <- rma(d_object$yi, d_object$vi)
d_low = d_object$ci.lb
d_high = d_object$ci.ub
if ((dz_low <= cohendz_true) && (dz_high >= cohend_true)) {dz_capture = dz_capture + 1}
if ((dz_better_low <= cohendz_true_better) && (dz_better_high >= cohendz_true_better)) {dz_better_capture = dz_better_capture + 1}
if ((d_low <= cohend_true) && (d_high >= cohend_true)) {d_capture = d_capture + 1}
samples_drawn = samples_drawn + 1
}
print(paste("N=", sample_size, "TrueMeanDiff=", mdiff_true, "Paired_Correlation=", ws_correlation, "SD=", pretest_sd, "Capture of Cohen dz=", dz_capture/samples_drawn, "Capture Bob's way=", dz_better_capture/samples_drawn, "Capture cohen's d", d_capture/samples_drawn, sep=" "))
#}
#}
#}
#}
for (sample_size in c(10, 15, 20, 25, 30, 35, 40, 45, 50)) {
for (posttest_mean in c(5, 5.5, 6, 6.5)) {
for (ws_correlation in c(0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)) {
for (pretest_sd in c(1, 1.5, 2)) {
posttest_sd = pretest_sd   #for now, let's assume variance is same at both tests, ideal case
#population values
mdiff_true = posttest_mean - pretest_mean
cohend_true = mdiff_true / sqrt((pretest_sd^2 + posttest_sd^2)/2)
population_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =TRUE)
sd_difference = sd(population_run[,2] - population_run[,1])
cohendz_true = mdiff_true / sd_difference
cohendz_true_better_obtject = escalc(measure="SMCR", m1i=posttest_mean, m2i=pretest_mean, sd1i=sd_difference, ni=sample_size, ri=ws_correlation)
cohendz_true_better = cohendz_true_better_obtject$yi[1]
#Now draw samples
dz_capture = 0
dz_better_capture = 0
d_capture = 0
samples_drawn = 0
for(samples in 1:samples_per_condition) {
this_run<-mvrnorm(sample_size, mu=c(pretest_mean,posttest_mean), Sigma = matrix(c(pretest_sd,ws_correlation, ws_correlation, posttest_sd), ncol=2), empirical =FALSE)
mdiff = mean(this_run[,2]) - mean(this_run[, 1])
#calculate dz and its CI as Masson emailed
sd_mdiff = sd (this_run[,2] - this_run[,1])
dz = mdiff / sd_mdiff
dz_sem = sd_mdiff / sqrt(sample_size - 1)
dz_moe = qt(0.975, sample_size - 1) * dz_sem
dz_low = dz - dz_moe
dz_high = dz + dz_moe
#calculate dz and its CI as Bob suggests
dz_better_object <- escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sd_mdiff, ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
dz_better_object <- rma(dz_better_object$yi, dz_better_object$vi)
dz_better_low = dz_better_object$ci.lb
dz_better_high = dz_better_object$ci.ub
d_object <-escalc(measure="SMCR", m1i=mean(this_run[,2]), m2i=mean(this_run[,1]), sd1i=sqrt( (sd(this_run[,1]^2 + sd(this_run[,2]^2) )/ 2) ), ni=sample_size, ri=cor(this_run[,1], this_run[,2]))
d_object <- rma(d_object$yi, d_object$vi)
d_low = d_object$ci.lb
d_high = d_object$ci.ub
if ((dz_low <= cohendz_true) && (dz_high >= cohend_true)) {dz_capture = dz_capture + 1}
if ((dz_better_low <= cohendz_true_better) && (dz_better_high >= cohendz_true_better)) {dz_better_capture = dz_better_capture + 1}
if ((d_low <= cohend_true) && (d_high >= cohend_true)) {d_capture = d_capture + 1}
samples_drawn = samples_drawn + 1
}
print(paste("N=", sample_size, "TrueMeanDiff=", mdiff_true, "Paired_Correlation=", ws_correlation, "SD=", pretest_sd, "Capture of Cohen dz=", dz_capture/samples_drawn, "Capture Bob's way=", dz_better_capture/samples_drawn, "Capture cohen's d", d_capture/samples_drawn, sep=" "))
}
}
}
}
d_object <-escalc(measure="SMCC", m1i=10, m2i=12, sd1i=1, ni=30, ri=0.7)
d_object <-escalc(measure="SMCR", m1i=10, m2i=12, sd1i=1, ni=30, ri=0.7)
d_object
d_object <-escalc(measure="SMCR", m1i=10, m2i=12, sd1i=1, sd2i=1, ni=30, ri=0.7)
dz_ci <- rma(d_object$vi, d_object$yi)
d_object <-escalc(measure="SMCR", m1i=10, m2i=12, sd1i=3, sd2i=3, ni=30, ri=0.7)
dz_ci <- rma(d_object$yi, d_object$vi)
dz_ci
library('metafor')
print(dz_ci)
install.packages("pwr")
library("pwr")
pwr.r.test(r = 0.25, sig.level = 0.05, power=0.80)
pwr.r.test(r = 0.50, sig.level = 0.05, power=0.80)
pwr.r.test(r = 0.50, sig.level = 0.05, N = 12)
? pwr.r.test
pwr.r.test(r = 0.50, sig.level = 0.05, n = 12)
pwr.r.test(r = 0.40, sig.level = 0.05, power=0.80)
pwr.r.test(r = 0.40, sig.level = 0.05, n = 12)
pwr.r.test(power = .8, sig.level = 0.05, n = 12)
library('userfriendlyscience')
dat <- data.frame(x1 = factor(rep(c(0,1), 20)),
x2 = factor(c(rep(0, 20), rep(1, 20))),
y=rep(c(4,5), 20) + rnorm(40));
meanDiff.multi(dat, x=c('x1', 'x2'), y='y', var.equal="yes");
ggConfidenceCurve(metric='d', value = .5, n = 128);
update.packages('userfriendlyscience')
library('userfriendlyscience')
ggConfidenceCurve(metric='d', value = .5, n = 128);
install.packages('userfriendlyscience')
install.packages("userfriendlyscience")
library('userfriendlyscience')
ggConfidenceCurve(metric='d', value = .5, n = 128);
ggConfidenceCurve(metric='d', value = .5, conf.level = .95);
install.packages(c("arm", "BH", "callr", "car", "curl", "data.table", "data.tree", "DiagrammeR", "digest", "doParallel", "dplyr", "evaluate", "fBasics", "foreach", "foreign", "GGally", "ggrepel", "gridExtra", "gss", "hermite", "hms", "htmlwidgets", "httpuv", "igraph", "irlba", "iterators", "knitr", "later", "lazyeval", "lme4", "MASS", "MBESS", "memoise", "metafor", "miniUI", "mosaic", "mosaicData", "multcomp", "mvtnorm", "NMF", "OpenMx", "pander", "plogr", "psych", "pwr", "quantreg", "Rcpp", "RcppEigen", "readxl", "registry", "reshape", "reshape2", "rio", "rJava", "rngtools", "rpf", "RSQLite", "sandwich", "scales", "SCRT", "shiny", "sourcetools", "StanHeaders", "stringi", "stringr", "tidyr", "timeDate", "timeSeries", "userfriendlyscience", "vegan", "viridis", "viridisLite", "visNetwork", "XML", "yaml", "zoo"))
install.packages(c("boot", "cluster", "foreign", "MASS", "Matrix", "mgcv", "rpart", "survival"), lib="C:/Program Files/R/R-3.3.3/library")
setwd("C:/Users/bob/Dropbox/Bob/Replication Projects/APS 2018 - Teaching New Stats/two_proportions - power")
# This source file has 3 helper functions that do all the calculaitons
source("proportions.R")
#let the user select a file
filename = file.choose(new = FALSE)
#Read the file and also record the base name of the file
pdata = read.csv(filename, header=TRUE, sep=",")
lab = trimws(sub(".csv", "", basename(filename)))
#calculate the difference between two proportions
estimate.diffproportions.rawdata(pdata, "Condition", "Response", 1, main=lab)
